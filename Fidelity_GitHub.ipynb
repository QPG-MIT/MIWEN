{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N8ViDOcuVu-F"
   },
   "source": [
    "### Import libraries and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 15935,
     "status": "ok",
     "timestamp": 1722439606718,
     "user": {
      "displayName": "Dirk Englund",
      "userId": "13834429622441934993"
     },
     "user_tz": 240
    },
    "id": "ua4XlYzhVu-H"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time, os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from scipy.constants import speed_of_light as c\n",
    "import scipy.io\n",
    "from collections import OrderedDict\n",
    "import torch.fft as tfft\n",
    "import datetime\n",
    "%matplotlib inline\n",
    "\n",
    "# gpu = torch.device(\"mps\")\n",
    "gpu = torch.device(\"cpu\")\n",
    "\n",
    "# ## Sets everything to double point precision (use with gradcheck)\n",
    "# torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 2925,
     "status": "ok",
     "timestamp": 1722439609642,
     "user": {
      "displayName": "Dirk Englund",
      "userId": "13834429622441934993"
     },
     "user_tz": 240
    },
    "id": "GVJBGShzVu-I"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mutual_info_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1722439609643,
     "user": {
      "displayName": "Dirk Englund",
      "userId": "13834429622441934993"
     },
     "user_tz": 240
    },
    "id": "HpegIK-RVu-I"
   },
   "outputs": [],
   "source": [
    "speedoflight = 3e8\n",
    "epsilon0 = 8.85e-12\n",
    "\n",
    "kb = torch.tensor(1.38e-23); T = torch.tensor(300)\n",
    "hbar = torch.tensor(1.05e-34)\n",
    "\n",
    "eleccharge = torch.tensor(1.6e-19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1722439609643,
     "user": {
      "displayName": "Dirk Englund",
      "userId": "13834429622441934993"
     },
     "user_tz": 240
    },
    "id": "61ckI9VBVu-I"
   },
   "outputs": [],
   "source": [
    "def boseeinstein(omega, T):\n",
    "\n",
    "    return 1/(torch.exp(hbar*omega/(kb*T))-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Physics module for MIWEN implementation containing physical constants,\n",
    "noise models, and mixing functions.\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import scipy.constants as const\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class PhysicalConstants:\n",
    "    \"\"\"Physical constants and device parameters\"\"\"\n",
    "    kb: float = const.k        # Boltzmann constant\n",
    "    T: float = 300.0          # Room temperature (K)\n",
    "    e: float = const.e        # Elementary charge\n",
    "    c: float = const.c        # Speed of light\n",
    "    h: float = const.h        # Planck constant\n",
    "    hbar: float = const.hbar  # Reduced Planck constant\n",
    "    R: float = 50.0          # Load resistance (Ω)\n",
    "    eta: float = 1.0    \n",
    "    \n",
    "    @property\n",
    "    def VT(self):\n",
    "        \"\"\"Thermal voltage\"\"\"\n",
    "        return self.eta * self.kb * self.T / self.e\n",
    "\n",
    "class NoiseModel:\n",
    "    \"\"\"Implements various noise models for the system\"\"\"\n",
    "    def __init__(self, constants: PhysicalConstants, bandwidth: float):\n",
    "        self.constants = constants\n",
    "        self.bandwidth = bandwidth\n",
    "    \n",
    "    def thermal_noise(self, signal: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Add Johnson-Nyquist noise to the signal\"\"\"\n",
    "        # Thermal noise power = 4kTR∆f\n",
    "        noise_power = 4 * self.constants.kb * self.constants.T * self.constants.R * self.bandwidth\n",
    "        noise_std = torch.sqrt(torch.tensor(noise_power))\n",
    "        noise = torch.randn_like(signal) * noise_std\n",
    "        return signal + noise\n",
    "\n",
    "    def shot_noise(self, signal: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Add shot noise (optional)\"\"\"\n",
    "        # TODO: Implement shot noise\n",
    "        return signal\n",
    "\n",
    "class DiodeMixing:\n",
    "    \"\"\"Implements different diode mixing models\"\"\"\n",
    "    def __init__(self, constants: PhysicalConstants, noise_model: NoiseModel):\n",
    "        self.constants = constants\n",
    "        self.noise_model = noise_model\n",
    "\n",
    "    def simple_mixing(self, z: torch.Tensor, w: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Simplified mixing with tanh for stability\"\"\"\n",
    "        z_noisy = self.noise_model.thermal_noise(z)\n",
    "        w_noisy = self.noise_model.thermal_noise(w)\n",
    "        return torch.tanh((z_noisy + w_noisy) / (2 * self.constants.VT))\n",
    "\n",
    "    def exact_mixing(self, z: torch.Tensor, w: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        EXACT diode formula with numerical stability:\n",
    "        out = w/2 + (VT/2)* log( (exp(z/VT)+ exp(-w/VT)) / (exp(z/VT)+ exp(w/VT)) )\n",
    "        \"\"\"\n",
    "#         z_noisy = self.noise_model.thermal_noise(z)\n",
    "#         w_noisy = self.noise_model.thermal_noise(w)\n",
    "        \n",
    "        VT = self.constants.VT\n",
    "        eps = 1e-8\n",
    "        \n",
    "        z_scaled = torch.clamp(z / VT, min=-50, max=50)\n",
    "        w_scaled = torch.clamp(w / VT, min=-50, max=50)\n",
    "        \n",
    "        max_val = torch.maximum(z_scaled, torch.maximum(w_scaled, -w_scaled))\n",
    "        numerator = torch.log(torch.exp(z_scaled - max_val) + torch.exp(-w_scaled - max_val) + eps) + max_val\n",
    "        denominator = torch.log(torch.exp(z_scaled - max_val) + torch.exp(w_scaled - max_val) + eps) + max_val\n",
    "        \n",
    "        out = (w/2.0) + (VT/2.0) * (numerator - denominator)\n",
    "        return torch.clamp(out, min=-1e3, max=1e3) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uQXKEhlMVu-I"
   },
   "source": [
    "### Custom layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Params:\n",
    "    def __init__(self, weightshape=None, red=True, units=1, fixedband=False, totBW=None,\n",
    "                 noisein=False, noiseout=False, lowtemp=False, weightfreqspacing=None,\n",
    "                 k_th_AWG=None, k_th_AWG_lowtemp=None, k_th_AWG_lowtemp_opt=None,\n",
    "                 k_th_w=None, k_th_out=None, k_th_w_lowtemp=None, k_th_out_lowtemp=None,\n",
    "                 k_th_w_lowtemp_opt=None, k_th_A2D=None, k_th_A2D_lowtemp=None,\n",
    "                 scaletoz=False, scaletoW=False, wunits=1, unitconverter=1,\n",
    "                 includeinputfft=False, includeoutputfft=False, semianalog=True,\n",
    "                 digitallike=False, noisefactor=4, optics=False,\n",
    "                 photodiodearea=1e-6, omegaoptical=2*torch.pi*193.41e12,\n",
    "                 inttime=1e-7, capval=1e-12, \n",
    "                 includecarrier=False, \n",
    "                 carrieroffmult=5):\n",
    "        \n",
    "        # Common attributes\n",
    "        self.weightshape = weightshape\n",
    "        self.red = red\n",
    "        self.units = units\n",
    "        self.fixedband = fixedband\n",
    "        self.totBW = totBW\n",
    "        self.noisein = noisein\n",
    "        self.noiseout = noiseout\n",
    "        self.lowtemp = lowtemp\n",
    "        self.weightfreqspacing = weightfreqspacing\n",
    "        self.digitallike = digitallike\n",
    "        self.noisefactor = noisefactor\n",
    "        self.optics = optics\n",
    "        self.photodiodearea = photodiodearea\n",
    "        self.omegaoptical = omegaoptical\n",
    "        self.inttime = inttime\n",
    "        self.capval = capval\n",
    "        \n",
    "        # FFT related\n",
    "        self.includeinputfft = includeinputfft\n",
    "        self.includeoutputfft = includeoutputfft\n",
    "        \n",
    "        # Weight encoding/mixing attributes\n",
    "        self.scaletoz = scaletoz\n",
    "        self.scaletoW = scaletoW\n",
    "        self.wunits = wunits\n",
    "        self.unitconverter = unitconverter\n",
    "\n",
    "        # Noise attributes\n",
    "        self.k_th_AWG = k_th_AWG\n",
    "        self.k_th_AWG_lowtemp = k_th_AWG_lowtemp\n",
    "        self.k_th_AWG_lowtemp_opt = k_th_AWG_lowtemp_opt\n",
    "\n",
    "        self.k_th_w = k_th_w\n",
    "        self.k_th_out = k_th_out\n",
    "        self.k_th_w_lowtemp = k_th_w_lowtemp\n",
    "        self.k_th_out_lowtemp = k_th_out_lowtemp\n",
    "        self.k_th_w_lowtemp_opt = k_th_w_lowtemp_opt\n",
    "\n",
    "        # A2D specific attributes\n",
    "        self.k_th_A2D = k_th_A2D\n",
    "        self.k_th_A2D_lowtemp = k_th_A2D_lowtemp\n",
    "        self.semianalog = semianalog\n",
    "        \n",
    "        self.includecarrier = includecarrier\n",
    "        self.carrieroffmult = carrieroffmult\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActivationEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, params: Params):\n",
    "        super(ActivationEncoding, self).__init__()\n",
    "        self.params = params\n",
    "\n",
    "        self.N = self.params.weightshape[1]\n",
    "        self.R = self.params.weightshape[0]\n",
    "\n",
    "        if self.params.red:\n",
    "            self.n0 = 0\n",
    "            self.r0 = self.R * (self.N - 1) / 2\n",
    "            if not self.params.includecarrier:\n",
    "                self.highestindex = int(2 * ((self.r0 + self.R) + (self.n0 + self.N) * self.R) + 4)\n",
    "                self.total = int(2 * (self.highestindex - 1))\n",
    "            else:\n",
    "                self.highestindex = int(2 * ( self.params.carrieroffmult*((self.r0 + self.R) + (self.n0 + self.N) * self.R) ) + 4)\n",
    "                self.total = int(2 * (self.highestindex - 1))\n",
    "        else:\n",
    "            self.n0 = int(self.N * (self.R - 1) / 2)\n",
    "            self.r0 = 0\n",
    "            if not self.params.includecarrier:\n",
    "                self.highestindex = int(2 * ((self.r0 + self.R) * self.N + (self.n0 + self.N)) + 4)\n",
    "                self.total = int(2 * (self.highestindex - 1))\n",
    "            else:\n",
    "                self.highestindex = int(2 * ( self.params.carrieroffmult*((self.r0 + self.R) * self.N + (self.n0 + self.N)) ) + 4)\n",
    "                self.total = int(2 * (self.highestindex - 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.params.includeinputfft:\n",
    "            x_complex = torch.complex(x, torch.zeros_like(x))\n",
    "            x = torch.fft.fft(x_complex.conj().t(), dim=0, norm=\"ortho\").conj().t()\n",
    "\n",
    "        if self.params.red:\n",
    "            inputs_extended = x.unsqueeze(2)\n",
    "            extendedshape = inputs_extended.shape\n",
    "            zeropaddingleft = torch.zeros(extendedshape[0], extendedshape[1], self.R - 1)\n",
    "            output_inter_tensor = torch.cat([zeropaddingleft, inputs_extended], dim=-1)\n",
    "            output_inter_tensor = output_inter_tensor.view(extendedshape[0], -1)\n",
    "            furtherzeropaddingleft = torch.zeros(extendedshape[0], self.n0 * self.R + 1)\n",
    "            output_inter_tensor = torch.cat([furtherzeropaddingleft, output_inter_tensor], dim=-1)\n",
    "            \n",
    "            if self.params.includecarrier:\n",
    "                extrabins = int((self.params.carrieroffmult-1)*((self.r0 + self.R) + (self.n0 + self.N) * self.R))\n",
    "                carrierzeropaddingleft = torch.zeros(extendedshape[0], extrabins)\n",
    "                output_inter_tensor = torch.cat([carrierzeropaddingleft, output_inter_tensor], dim=-1)\n",
    "            \n",
    "            zeropaddingright = torch.zeros(extendedshape[0], self.highestindex - output_inter_tensor.shape[-1])\n",
    "            y = torch.cat([output_inter_tensor, zeropaddingright], dim=-1)\n",
    "            x = torch.real(torch.fft.irfft(y, dim=-1, norm=\"ortho\"))\n",
    "            xener = torch.sum(x ** 2, dim=-1)\n",
    "        else:\n",
    "            xshape = x.shape\n",
    "            zeropaddingleft = torch.zeros(xshape[0], self.n0 + 1)\n",
    "            output_inter_tensor = torch.cat([zeropaddingleft, x], dim=-1)\n",
    "            \n",
    "            if self.params.includecarrier:\n",
    "                extrabins = int((self.params.carrieroffmult-1)*((self.r0 + self.R) * self.N + (self.n0 + self.N))) \n",
    "                carrierzeropaddingleft = torch.zeros(xshape[0], extrabins)\n",
    "                output_inter_tensor = torch.cat([carrierzeropaddingleft, output_inter_tensor], dim=-1)\n",
    "            \n",
    "            zeropaddingright = torch.zeros(xshape[0], self.highestindex - output_inter_tensor.shape[-1])\n",
    "            y = torch.cat([output_inter_tensor, zeropaddingright], dim=-1)\n",
    "            x = torch.real(torch.fft.irfft(y, dim=-1, norm=\"ortho\"))\n",
    "            xener = torch.sum(x ** 2, dim=-1)\n",
    "\n",
    "        # adding noise in the time domain\n",
    "        if self.params.noisein:\n",
    "            if not self.params.optics:\n",
    "                noisetouse = self.params.k_th_AWG_lowtemp if self.params.lowtemp else self.params.k_th_AWG\n",
    "                sigma2_x_th = (\n",
    "                    noisetouse * self.params.weightfreqspacing * self.total\n",
    "                    if not self.params.fixedband\n",
    "#                     else noisetouse * self.params.totBW\n",
    "                    else noisetouse * (omegac/(2*np.pi))\n",
    "                )\n",
    "                if self.params.digitallike:\n",
    "                    sigma2_x_th = sigma2_x_th*self.params.noisefactor\n",
    "#                 xadditivenoise = torch.normal(0., torch.sqrt(torch.tensor(sigma2_x_th)), size=x.shape)\n",
    "                xadditivenoise = torch.normal(0., torch.sqrt(sigma2_x_th), size=x.shape)\n",
    "                x = x + xadditivenoise\n",
    "\n",
    "        return x, xener\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "izUQ4ZWHVu-J"
   },
   "outputs": [],
   "source": [
    "class WeightEncodingandMixing(nn.Module):\n",
    "\n",
    "    def __init__(self, params: Params, diodemixer):\n",
    "        super(WeightEncodingandMixing, self).__init__()\n",
    "\n",
    "        self.params = params\n",
    "\n",
    "        self.N = self.params.weightshape[1]\n",
    "        self.R = self.params.weightshape[0]\n",
    "        \n",
    "        self.diodemixer = diodemixer\n",
    "\n",
    "        if self.params.red:\n",
    "            self.n0 = 0\n",
    "            self.r0 = self.R * (self.N - 1) / 2\n",
    "            if not self.params.includecarrier:\n",
    "                self.highestindex = int(2 * ((self.r0 + self.R) + (self.n0 + self.N) * self.R) + 4)\n",
    "                self.total = int(2 * (self.highestindex - 1))\n",
    "            else:\n",
    "                self.highestindex = int(2 * ( self.params.carrieroffmult*((self.r0 + self.R) + (self.n0 + self.N) * self.R) ) + 4)\n",
    "                self.total = int(2 * (self.highestindex - 1))\n",
    "                \n",
    "        else:\n",
    "            self.n0 = int(self.N * (self.R - 1) / 2)\n",
    "            self.r0 = 0\n",
    "            if not self.params.includecarrier:\n",
    "                self.highestindex = int(2 * ((self.r0 + self.R) * self.N + (self.n0 + self.N)) + 4)\n",
    "                self.total = int(2 * (self.highestindex - 1))\n",
    "            else:\n",
    "                self.highestindex = int(2 * ( self.params.carrieroffmult*((self.r0 + self.R) * self.N + (self.n0 + self.N)) ) + 4)\n",
    "                self.total = int(2 * (self.highestindex - 1))\n",
    "\n",
    "        complex_tensor = torch.empty(*self.params.weightshape, dtype=torch.complex64)\n",
    "        nn.init.kaiming_uniform_(complex_tensor.real, a=0)\n",
    "        complex_tensor.imag.zero_()\n",
    "        self.W = nn.Parameter(complex_tensor)\n",
    "\n",
    "    def forward(self, z):\n",
    "        if self.params.red:\n",
    "            if not self.params.includeinputfft and not self.params.includeoutputfft:\n",
    "                Wtr = self.W.t()\n",
    "            else:\n",
    "                selfW = self.W.to(dtype=torch.complex64)\n",
    "\n",
    "                if self.params.includeoutputfft:\n",
    "                    selfW = torch.fft.fft(selfW, dim=0, norm=\"ortho\")\n",
    "\n",
    "                if self.params.includeinputfft:\n",
    "                    selfW = torch.fft.fft(selfW.conj().t(), dim=0, norm=\"ortho\").conj().t()\n",
    "\n",
    "                Wtr = selfW.t()\n",
    "\n",
    "            Wunrolled = Wtr.reshape(-1)\n",
    "            zeropaddingleft = torch.zeros(int(self.r0 + 1 + (self.n0 + 1) * self.R))\n",
    "            Wpaddedleft = torch.cat([zeropaddingleft, Wunrolled], dim=-1)\n",
    "            \n",
    "            if self.params.includecarrier:\n",
    "                extrabins = int((self.params.carrieroffmult-1)*((self.r0 + self.R) + (self.n0 + self.N) * self.R)) \n",
    "                carrierzeropaddingleft = torch.zeros(extrabins)\n",
    "                Wpaddedleft = torch.cat([carrierzeropaddingleft, Wpaddedleft], dim=-1)\n",
    "            \n",
    "            zeropaddingright = torch.zeros(self.highestindex - Wpaddedleft.shape[-1])\n",
    "            Wpadded = torch.cat([Wpaddedleft, zeropaddingright], dim=-1)\n",
    "            Wtime = torch.real(torch.fft.irfft(Wpadded, dim=-1, norm=\"ortho\").unsqueeze(0))\n",
    "        else:\n",
    "            if not self.params.includeinputfft:\n",
    "                Wunrolled = self.W.reshape(-1)\n",
    "            else:\n",
    "                FW = fourier_matrix(self.R) @ self.W\n",
    "                Wunrolled = FW.reshape(-1)\n",
    "\n",
    "            zeropaddingleft = torch.zeros(int((self.r0 + 1) * self.N + (self.n0 + 1)))\n",
    "            Wpaddedleft = torch.cat([zeropaddingleft, Wunrolled], dim=-1)\n",
    "            zeropaddingright = torch.zeros(self.highestindex - Wpaddedleft.shape[-1])\n",
    "            Wpadded = torch.cat([Wpaddedleft, zeropaddingright], dim=-1)\n",
    "            Wtime = torch.real(torch.fft.irfft(Wpadded, dim=-1, norm=\"ortho\").unsqueeze(0))\n",
    "\n",
    "        if self.params.noisein:\n",
    "            if not self.params.optics:\n",
    "                noisetouse = self.params.k_th_w_lowtemp if self.params.lowtemp else self.params.k_th_w\n",
    "                sigma2_W_th = (noisetouse * self.params.weightfreqspacing * self.total\n",
    "                               if not self.params.fixedband\n",
    "#                                else noisetouse * self.params.totBW\n",
    "                               else noisetouse * (omegac/(2*np.pi)))\n",
    "\n",
    "                if self.params.digitallike:\n",
    "                    sigma2_W_th = sigma2_W_th*self.params.noisefactor\n",
    "\n",
    "#                 Wadditivenoise = torch.normal(0., torch.sqrt(torch.tensor(sigma2_W_th)), size=Wtime.shape)\n",
    "                Wadditivenoise = torch.normal(0., torch.sqrt(sigma2_W_th), size=Wtime.shape)\n",
    "                Wtime = Wtime + Wadditivenoise\n",
    "\n",
    "        if not self.params.optics:\n",
    "#             outputs_in_time = (1 / (4 * (kb * T / eleccharge))) * torch.mul(z, Wtime)\n",
    "            outputs_in_time = self.diodemixer.exact_mixing(z, Wtime)\n",
    "        else:\n",
    "            upper_out = (z + Wtime) / torch.sqrt(torch.tensor(2))\n",
    "            lower_out = (z - Wtime) / torch.sqrt(torch.tensor(2))\n",
    "            nth = boseeinstein(self.params.omegaoptical, T)\n",
    "\n",
    "            upper_var = nth + nth**2 + (2 * nth + 1) * upper_out**2\n",
    "            lower_var = nth + nth**2 + (2 * nth + 1) * lower_out**2\n",
    "            diff_current = eleccharge * torch.normal(mean=2 * z * Wtime,\n",
    "                                                     std=torch.sqrt(upper_var + lower_var))\n",
    "\n",
    "            outputs_in_time = diff_current / self.params.capval\n",
    "\n",
    "        if not self.params.optics and self.params.scaletoz:\n",
    "            outputs_in_time = F.normalize(outputs_in_time, p=2, dim=-1)\n",
    "            znorm = torch.norm(z, p=2, dim=-1, keepdim=True)\n",
    "            outputs_in_time = torch.mul(znorm, outputs_in_time)\n",
    "\n",
    "        if not self.params.optics and self.params.scaletoW:\n",
    "            outputs_in_time = F.normalize(outputs_in_time, p=2, dim=-1)\n",
    "            Wnorm = torch.norm(Wtime, p=2, dim=-1, keepdim=True)\n",
    "            outputs_in_time = torch.mul(Wnorm, outputs_in_time)\n",
    "\n",
    "        outputs_in_time = outputs_in_time * self.params.unitconverter\n",
    "\n",
    "        if self.params.noiseout:\n",
    "            noisetouse = self.params.k_th_out_lowtemp if self.params.lowtemp else self.params.k_th_out\n",
    "            sigma2_output_th = (noisetouse * self.params.weightfreqspacing * self.total\n",
    "                                if not self.params.fixedband\n",
    "#                                 else noisetouse * self.params.totBW\n",
    "                                else noisetouse * (omegac/(2*np.pi)))\n",
    "\n",
    "            if not self.params.digitallike:\n",
    "                output_additivenoise = torch.normal(0., torch.sqrt(sigma2_output_th), size=Wtime.shape)\n",
    "                outputs_in_time = outputs_in_time + output_additivenoise\n",
    "\n",
    "        return outputs_in_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "VVXrV2k6Vu-J"
   },
   "outputs": [],
   "source": [
    "class A2D(nn.Module):\n",
    "\n",
    "    def __init__(self, params: Params):\n",
    "        super(A2D, self).__init__()\n",
    "\n",
    "        self.params = params\n",
    "\n",
    "#         if self.params.noiseout:\n",
    "        self.N = self.params.weightshape[1]\n",
    "        self.R = self.params.weightshape[0]\n",
    "\n",
    "        if self.params.red:\n",
    "            self.n0 = 0\n",
    "            self.r0 = self.R * (self.N - 1) / 2\n",
    "            if not self.params.includecarrier:\n",
    "                self.highestindex = int(2 * ((self.r0 + self.R) + (self.n0 + self.N) * self.R) + 4)\n",
    "                self.total = int(2 * (self.highestindex - 1))\n",
    "            else:\n",
    "                self.highestindex = int(2 * ( self.params.carrieroffmult*((self.r0 + self.R) + (self.n0 + self.N) * self.R) ) + 4)\n",
    "                self.total = int(2 * (self.highestindex - 1))\n",
    "        else:\n",
    "            self.n0 = int(self.N * (self.R - 1) / 2)\n",
    "            self.r0 = 0\n",
    "            if not self.params.includecarrier:\n",
    "                self.highestindex = int(2 * ((self.r0 + self.R) * self.N + (self.n0 + self.N)) + 4)\n",
    "                self.total = int(2 * (self.highestindex - 1))\n",
    "            else:\n",
    "                self.highestindex = int(2 * ( self.params.carrieroffmult*((self.r0 + self.R) * self.N + (self.n0 + self.N)) ) + 4)\n",
    "                self.total = int(2 * (self.highestindex - 1))\n",
    "\n",
    "    def forward(self, outputs_in_time):\n",
    "        if self.params.noiseout:\n",
    "            noisetouse = self.params.k_th_A2D_lowtemp if self.params.lowtemp else self.params.k_th_A2D\n",
    "\n",
    "            if not self.params.fixedband:\n",
    "                sigma2_A2D_th = noisetouse * self.params.weightfreqspacing * self.total\n",
    "            else:\n",
    "#                 sigma2_A2D_th = noisetouse * self.params.totBW\n",
    "                sigma2_A2D_th = noisetouse * (omegac/(2*np.pi))\n",
    "\n",
    "            if self.params.semianalog:\n",
    "                sigma2_A2D_th = sigma2_A2D_th*self.params.noisefactor\n",
    "\n",
    "            if not self.params.digitallike:\n",
    "                additivenoise = torch.normal(0., torch.sqrt(sigma2_A2D_th), size=outputs_in_time.shape)\n",
    "                outputs_in_time = outputs_in_time + additivenoise\n",
    "\n",
    "        if self.params.optics:\n",
    "            outputs_in_time = outputs_in_time * self.params.capval / (2 * eleccharge)\n",
    "        else:\n",
    "            outputs_in_time = outputs_in_time * 4 * (kb * T / eleccharge)\n",
    "\n",
    "        outputs_in_freq = torch.sqrt(torch.tensor(self.total)) * torch.real(torch.fft.rfft(outputs_in_time, dim=-1, norm=\"ortho\"))\n",
    "        \n",
    "        return outputs_in_freq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "cA9ZFS5HVu-J"
   },
   "outputs": [],
   "source": [
    "class MAFTFilter(nn.Module):\n",
    "\n",
    "    def __init__(self, params: Params):\n",
    "        super(MAFTFilter, self).__init__()\n",
    "\n",
    "        self.params = params\n",
    "\n",
    "        self.N = self.params.weightshape[1]\n",
    "        self.R = self.params.weightshape[0]\n",
    "\n",
    "        if self.params.red:\n",
    "            self.r0 = self.R * (self.N - 1) / 2\n",
    "        else:\n",
    "            self.r0 = 0\n",
    "\n",
    "    def forward(self, z):\n",
    "\n",
    "        if self.params.red:\n",
    "            z = z[:, int(self.r0 + 1):int(self.r0 + self.R + 1)]\n",
    "        else:\n",
    "            z = z[:, int((self.r0 + 1) * self.N):int((self.r0 + self.R) * self.N + 1):int(self.N)]\n",
    "\n",
    "        if self.params.includeoutputfft:\n",
    "            z_complex = torch.complex(z, torch.zeros_like(z))\n",
    "            z = torch.fft.ifft(z_complex.t(), dim=0, norm=\"ortho\").t().real\n",
    "\n",
    "        return z\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N0yVKb8aVu-K"
   },
   "source": [
    "### Make the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnaNetwork1layer(nn.Module):\n",
    "\n",
    "    def __init__(self, params: Params, outputsize, inputsize, diodemixer):\n",
    "        super(AnaNetwork1layer, self).__init__()\n",
    "\n",
    "        self.params = params\n",
    "        \n",
    "        self.diodemixer = diodemixer\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        if self.params.semianalog:\n",
    "\n",
    "            self.analogprepro = ActivationEncoding(self.params)\n",
    "\n",
    "            self.analoglayer = WeightEncodingandMixing(self.params, self.diodemixer)\n",
    "\n",
    "            self.A2D = A2D(self.params)\n",
    "\n",
    "        else:\n",
    "\n",
    "            # Even though semianalog is False, we pass the same params, as nothing changes structurally\n",
    "            self.analogprepro = ActivationEncoding(self.params)\n",
    "\n",
    "            self.analoglayer = WeightEncodingandMixing(self.params)\n",
    "\n",
    "            self.A2D = A2D(self.params)\n",
    "\n",
    "        self.filter = MAFTFilter(self.params)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.flatten(x)\n",
    "\n",
    "        x, _ = self.analogprepro(x)\n",
    "\n",
    "        x = self.analoglayer(x)\n",
    "\n",
    "        x = self.A2D(x)\n",
    "\n",
    "        x = self.filter(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 191,
     "status": "ok",
     "timestamp": 1722439609830,
     "user": {
      "displayName": "Dirk Englund",
      "userId": "13834429622441934993"
     },
     "user_tz": 240
    },
    "id": "CCAZEzZMVu-K"
   },
   "outputs": [],
   "source": [
    "preprounits = torch.tensor(1) # current in A\n",
    "wunits = torch.tensor(1) # voltage in V\n",
    "\n",
    "unitconverter = torch.tensor(1) # converts voltage to conductance,\n",
    "                                # and also has a unitless voltage divider like factor\n",
    "\n",
    "R_AWG = 50; R_w = 50; R_out = 50; R_A2D = 50\n",
    "\n",
    "weightfreqspacing = torch.tensor(1e3) # in Hz, 1 kHz\n",
    "timespan = 1/weightfreqspacing\n",
    "totalweightbandwidth = torch.tensor(1e8) # in Hz, 100 MHz\n",
    "numcomblines = totalweightbandwidth/weightfreqspacing # which is the number of MACs\n",
    "\n",
    "R_trans = torch.tensor(50) # ohms\n",
    "RF_power = torch.tensor(250e-6) # Watts\n",
    "Vref = torch.sqrt(RF_power*R_trans)\n",
    "\n",
    "analogenergyperMAC = RF_power*timespan/numcomblines\n",
    "\n",
    "k_th_AWG = 4*kb*T*R_AWG; k_th_w = 4*kb*T*R_w; k_th_out = 4*kb*T*R_out; k_th_A2D = 4*kb*T*R_A2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9JhYHXKsVu-K"
   },
   "source": [
    "## Multifreq plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fidelity(outputsize, inputsize, params, diodemixer, \n",
    "             scalefact=1., numtrials=1000, weightscalefact=None,\n",
    "             omegac=None, omegadiff=None, total=None, uni=True):\n",
    "\n",
    "    if not params.optics:\n",
    "        params.k_th_AWG_lowtemp = 2 * (hbar * omegac * np.cosh(hbar * omegac / (2 * kb * T)) / np.sinh(hbar * omegac / (2 * kb * T))) * R_AWG\n",
    "        params.k_th_w_lowtemp = 2 * (hbar * omegac * np.cosh(hbar * omegac / (2 * kb * T)) / np.sinh(hbar * omegac / (2 * kb * T))) * R_w\n",
    "        params.k_th_out_lowtemp = 2 * (hbar * omegac * np.cosh(hbar * omegac / (2 * kb * T)) / np.sinh(hbar * omegac / (2 * kb * T))) * R_out\n",
    "        params.k_th_A2D_lowtemp = 2 * (hbar * omegac * np.cosh(hbar * omegac / (2 * kb * T)) / np.sinh(hbar * omegac / (2 * kb * T))) * R_A2D\n",
    "\n",
    "        k_th_AWG_lowtemp_opt = None\n",
    "        k_th_w_lowtemp_opt = None\n",
    "    else:\n",
    "\n",
    "        params.k_th_AWG_lowtemp = 2 * (hbar * omegadiff * np.cosh(hbar * omegadiff / (2 * kb * T)) / np.sinh(hbar * omegadiff / (2 * kb * T))) * R_AWG\n",
    "        params.k_th_w_lowtemp = 2 * (hbar * omegadiff * np.cosh(hbar * omegadiff / (2 * kb * T)) / np.sinh(hbar * omegadiff / (2 * kb * T))) * R_w\n",
    "        params.k_th_out_lowtemp = 2 * (hbar * omegadiff * np.cosh(hbar * omegadiff / (2 * kb * T)) / np.sinh(hbar * omegadiff / (2 * kb * T))) * R_out\n",
    "        params.k_th_A2D_lowtemp = 2 * (hbar * omegadiff * np.cosh(hbar * omegadiff / (2 * kb * T)) / np.sinh(hbar * omegadiff / (2 * kb * T))) * R_A2D\n",
    "\n",
    "    # Refactored the network creation to use the params object\n",
    "    my_network = AnaNetwork1layer(params, outputsize, inputsize, diodemixer)\n",
    "\n",
    "    # Randomly generate matrix and input vector\n",
    "    if not uni:\n",
    "        weights = weightscalefact * torch.randn(outputsize, inputsize, dtype=torch.float64)\n",
    "    else:\n",
    "        weights = weightscalefact * (2*torch.rand(outputsize, inputsize, dtype=torch.float64)-1)\n",
    "    \n",
    "    my_network.analoglayer.W.data = weights\n",
    "    \n",
    "    if not uni:\n",
    "        inputs = scalefact * torch.randn(numtrials, inputsize, dtype=torch.float64)\n",
    "    else:\n",
    "        inputs = scalefact * (2*torch.rand(numtrials, inputsize, dtype=torch.float64)-1)\n",
    "\n",
    "    analogout = my_network(inputs)\n",
    "\n",
    "    target = (weights @ inputs.t()).t()\n",
    "\n",
    "    return analogout, target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nsr_vs_energy(params, diodemixer, stddev=1, optics=False, \n",
    "                  inputsize=1000, outputsize=1, \n",
    "                  omegac=2*np.pi*1e9, omegadiff=2*np.pi*1e9, \n",
    "                  totalweightenergyopt=1e-12, totalweightenergyrf=1e-12,\n",
    "                  energiespermac=None, numtrials=100, \n",
    "                  uni=True, \n",
    "                  maxsnr=True):\n",
    "\n",
    "    results = []\n",
    "\n",
    "    if optics:\n",
    "        weightenergypermacopt = totalweightenergyopt / inputsize\n",
    "    else:\n",
    "        weightenergypermacrf = totalweightenergyrf / inputsize\n",
    "\n",
    "    if params.red:\n",
    "        n0 = 0\n",
    "        r0 = outputsize * (inputsize - 1) / 2\n",
    "        highestindex = int(2 * ((r0 + outputsize) + (n0 + inputsize) * outputsize) + 4)\n",
    "        total = int(2 * (highestindex - 1))\n",
    "    else:\n",
    "        n0 = int(inputsize * (outputsize - 1) / 2)\n",
    "        r0 = 0\n",
    "        highestindex = int(2 * ((r0 + outputsize) * inputsize + (n0 + inputsize)) + 4)\n",
    "        total = int(2 * (highestindex - 1))\n",
    "\n",
    "#     delta_t = torch.tensor(1 / params.totBW, dtype=torch.float64)\n",
    "    delta_t = torch.tensor(1 / (omegac/(2*np.pi)), dtype=torch.float64)\n",
    "\n",
    "    for index, energypermac in enumerate(energiespermac):\n",
    "\n",
    "        if optics:\n",
    "            scalefact = torch.sqrt(energypermac / (hbar * omegac * stddev**2))\n",
    "            weightscalefact = torch.sqrt(weightenergypermacopt / (hbar * omegac * stddev**2))\n",
    "            noisefactor = 4\n",
    "        else:\n",
    "            scalefact = torch.sqrt(energypermac * R_trans / (delta_t * stddev**2))\n",
    "            weightscalefact = torch.sqrt(weightenergypermacrf * R_trans / (delta_t * stddev**2))\n",
    "            noisefactor = 4\n",
    "\n",
    "        # Call fidelity function using the params object\n",
    "        analogout, target = fidelity(outputsize, inputsize,\n",
    "                                     params, diodemixer,\n",
    "                                     scalefact=scalefact,\n",
    "                                     weightscalefact=weightscalefact,\n",
    "                                     numtrials=numtrials,\n",
    "                                     omegac=omegac,\n",
    "                                     omegadiff=omegadiff,\n",
    "                                     total=total, \n",
    "                                     uni=uni)\n",
    "        \n",
    "        if not maxsnr:\n",
    "            result = torch.mean((analogout - target).flatten()**2) / torch.mean(target.flatten()**2)\n",
    "        else:\n",
    "            result = torch.mean((analogout - target).flatten()**2) / (inputsize*scalefact*weightscalefact)**2\n",
    "\n",
    "        results.append(result)\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import LinearSegmentedColormap, Normalize\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "def plot_contour_with_dual_axes(start, end, ENOBrf, energiespermac, wbw=0.25e8, \n",
    "                                dukeplot=False, optics=False, uni=False, maxsnr=False, \n",
    "                                noisein=False, noiseout=True):\n",
    "    \"\"\"\n",
    "    Plots a contour plot with power (W) on the bottom and left axes \n",
    "    and energy (J) on the top and right axes.\n",
    "    \n",
    "    The colorbar is positioned so it does not cover the right-side axis labels.\n",
    "    The primary (bottom/left) axes are in log10(power), and the twin (top/right) \n",
    "    axes are in log10(energy). Ticks on both sets of axes are aligned exactly.\n",
    "    \"\"\"\n",
    "    # 1) Convert energy -> power using tbin = 1 / wbw\n",
    "    tbin = 1 / wbw\n",
    "    powers = energiespermac / tbin  # For your data and contours\n",
    "    \n",
    "    fontsize = 13.5\n",
    "\n",
    "    # 2) Convert those power values to log scale for contour plotting\n",
    "    x_power = np.log10(powers)\n",
    "    y_power = np.log10(powers)\n",
    "    X, Y = np.meshgrid(x_power, y_power)\n",
    "\n",
    "    # 3) Define a custom colormap\n",
    "    colors = [(0.8, 0.0, 0.0), (0.85, 0.85, 0.0), (0.0, 0.8, 0.0)]\n",
    "    cmap_custom = LinearSegmentedColormap.from_list(\"BlueGreenYellow\", colors, N=256)\n",
    "\n",
    "    # 4) Normalize the color mapping\n",
    "    norm = Normalize(vmin=np.min(ENOBrf), vmax=np.max(ENOBrf))\n",
    "\n",
    "    # 5) Create figure and main axes (for power)\n",
    "    fig, ax_power = plt.subplots(figsize=(6, 5))\n",
    "\n",
    "    # 6) Contour plot using the power domain\n",
    "    contour_levels = np.arange(1, np.ceil(np.max(ENOBrf)) + 1, 1)\n",
    "    CS = ax_power.contour(X, Y, ENOBrf, levels=contour_levels, \n",
    "                          linewidths=2.5, cmap=cmap_custom, norm=norm)\n",
    "    ax_power.clabel(CS, inline=True, fontsize=fontsize, colors='black')\n",
    "    \n",
    "    if dukeplot:\n",
    "        # marking Zhihui's points\n",
    "        points_power = [\n",
    "        (np.log10(0.5e-3), np.log10(0.5e-9)),\n",
    "        (np.log10(0.5e-3), np.log10(0.5e-8)),\n",
    "        (np.log10(0.5e-3), np.log10(0.5e-7)),\n",
    "        ]\n",
    "\n",
    "        for (px, py) in points_power:\n",
    "            ax_power.plot(px, py, '*', markersize=12, color='black')\n",
    "\n",
    "    # 7) Label the main (power) axes\n",
    "    ax_power.set_xlabel('Client power (W)', fontsize=fontsize)\n",
    "    ax_power.set_ylabel('Server power (W)', fontsize=fontsize)\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    #   A) CHOOSE DESIRED ENERGY TICKS (these are the \"most important\" ticks)\n",
    "    #      For example, from 1e-17 to 1e-8 in integer log steps\n",
    "    # -------------------------------------------------------------------------\n",
    "#     start, end = -17, -8  # you can adjust as desired\n",
    "    desired_energy_ticks = [10.0**i for i in range(start, end+1)]\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    #   B) CONVERT THESE ENERGY TICKS TO POWER (in linear space), \n",
    "    #      THEN TO log10(POWER) FOR THE MAIN AXIS\n",
    "    # -------------------------------------------------------------------------\n",
    "    power_tick_positions = [np.log10(E / tbin) for E in desired_energy_ticks]\n",
    "    # We'll label them in scientific notation\n",
    "    power_tick_labels = [f\"{(E / tbin):.1e}\" for E in desired_energy_ticks]\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    #   C) APPLY THOSE TICKS TO THE MAIN (POWER) AXES\n",
    "    # -------------------------------------------------------------------------\n",
    "    # X-axis\n",
    "    ax_power.set_xticks(power_tick_positions[::2])\n",
    "    ax_power.set_xticklabels(power_tick_labels[::2], fontsize=fontsize)\n",
    "    # Y-axis\n",
    "    ax_power.set_yticks(power_tick_positions[::2])\n",
    "    ax_power.set_yticklabels(power_tick_labels[::2], fontsize=fontsize)\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    #   D) CREATE TWIN AXES FOR ENERGY (TOP AND RIGHT)\n",
    "    # -------------------------------------------------------------------------\n",
    "    ax_energy_top = ax_power.twiny()\n",
    "    ax_energy_right = ax_power.twinx()\n",
    "\n",
    "    # We'll use a log scale for these axes\n",
    "    ax_energy_top.set_xscale('log')\n",
    "    ax_energy_right.set_yscale('log')\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    #   E) SET TICKS FOR THE ENERGY AXES\n",
    "    # -------------------------------------------------------------------------\n",
    "    # Top axis (client energy)\n",
    "    ax_energy_top.set_xticks(desired_energy_ticks[::2])\n",
    "    ax_energy_top.xaxis.set_major_formatter(ticker.FormatStrFormatter('%.0e'))\n",
    "    ax_energy_top.tick_params(axis='x', labelsize=fontsize)\n",
    "    ax_energy_top.set_xlabel('Client energy per MAC (J)', fontsize=fontsize, labelpad=12)\n",
    "\n",
    "    # Right axis (server energy)\n",
    "    ax_energy_right.set_yticks(desired_energy_ticks[::2])\n",
    "    ax_energy_right.yaxis.set_major_formatter(ticker.FormatStrFormatter('%.0e'))\n",
    "    ax_energy_right.tick_params(axis='y', labelsize=fontsize)\n",
    "    ax_energy_right.set_ylabel('Server energy per MAC (J)', fontsize=fontsize, \n",
    "                               rotation=-90, labelpad=20)\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    #   F) FORCE THE MAIN AXES LIMITS & MATCH THE TWIN AXES LIMITS\n",
    "    #      so that the top/right truly align with bottom/left\n",
    "    #\n",
    "    #   The main axis is in log10(power), so let's set xlim/ylim to \n",
    "    #   the first and last tick positions in log10(POWER).\n",
    "    #\n",
    "    #   Then for the twin axes (in energy), we apply the same range \n",
    "    #   but in linear scale for energy = 10^(log10(power)) * tbin.\n",
    "    # -------------------------------------------------------------------------\n",
    "    xmin_p, xmax_p = power_tick_positions[0], power_tick_positions[-1]\n",
    "    ax_power.set_xlim(xmin_p, xmax_p)\n",
    "    ax_power.set_ylim(xmin_p, xmax_p)\n",
    "\n",
    "    # For the twin top axis: E = P * tbin, so in linear scale that is\n",
    "    # from 10^xmin_p * tbin to 10^xmax_p * tbin\n",
    "    ax_energy_top.set_xlim(10**xmin_p * tbin, 10**xmax_p * tbin)\n",
    "    # For the twin right axis: same approach for y-limits\n",
    "    ax_energy_right.set_ylim(10**xmin_p * tbin, 10**xmax_p * tbin)\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    #   G) Grid and style adjustments\n",
    "    # -------------------------------------------------------------------------\n",
    "    for spine in ax_power.spines.values():\n",
    "        spine.set_linewidth(1.5)\n",
    "    ax_power.grid(True, linestyle=(0, (1, 3)), linewidth=2)\n",
    "\n",
    "    # Adjust layout so the colorbar doesn't overlap the right axis\n",
    "    fig.subplots_adjust(right=0.85)\n",
    "\n",
    "    # -------------------------------------------------------------------------\n",
    "    #   H) Add the colorbar on the right\n",
    "    # -------------------------------------------------------------------------\n",
    "    sm = plt.cm.ScalarMappable(cmap=CS.cmap, norm=CS.norm)\n",
    "    sm.set_array([])\n",
    "\n",
    "    cbar_ax = fig.add_axes([1.02, 0.15, 0.03, 0.7])  # [left, bottom, width, height]\n",
    "    colorbar = plt.colorbar(sm, cax=cbar_ax)\n",
    "    colorbar.ax.tick_params(labelsize=fontsize)\n",
    "    colorbar.outline.set_linewidth(1.5)\n",
    "    if not optics:\n",
    "        colorbar.set_label('RF mixer output effective number of bits', fontsize=fontsize, \n",
    "                           rotation=270, labelpad=15)\n",
    "    else:\n",
    "        colorbar.set_label('Homodyne output effective number of bits', fontsize=fontsize, \n",
    "                           rotation=270, labelpad=15)\n",
    "#     fig.suptitle(\"RF output bit precision\", fontsize=fontsize+2, y=1.02)\n",
    "\n",
    "    if not optics:\n",
    "        plt.savefig(f\"Figures/ENOB_rf_2D_Jun3_eta{eta}_uni{uni}_maxsnr{maxsnr}_noisein{noisein}_noiseout{noiseout}.pdf\", bbox_inches='tight')\n",
    "    else:\n",
    "        plt.savefig(f\"Figures/ENOB_optics_2D_Jun3_uni{uni}_maxsnr{maxsnr}.pdf\", bbox_inches='tight')\n",
    "\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the start and end of the log scale\n",
    "start = -17  # log10(1e-20)\n",
    "end = -10   # log10(1e-11)\n",
    "\n",
    "# Define the number of points in the tensor\n",
    "num_points = 16  # You can adjust this number as needed, was 37\n",
    "\n",
    "# Create the tensor with log-spaced values\n",
    "energiespermac = torch.logspace(start, end, steps=num_points, dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "includecarrier = True\n",
    "\n",
    "carrieroffmult = 40 # UHF cell\n",
    "totBW = torch.tensor(0.25e8, dtype=torch.float64)\n",
    "\n",
    "UHFfreq = carrieroffmult*totBW # UHF cell\n",
    "\n",
    "omegac = 2*np.pi*UHFfreq\n",
    "\n",
    "inputsize = 256\n",
    "outputsize = 1\n",
    "\n",
    "eta = 1.\n",
    "\n",
    "noisein = True\n",
    "noiseout = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "constants = PhysicalConstants(eta=eta)\n",
    "noisemodel = NoiseModel(constants=constants, bandwidth=0.25e8)\n",
    "\n",
    "diodemixer = DiodeMixing(constants=constants, noise_model=noisemodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramsrf = Params(weightshape=[outputsize, inputsize], red=True, units=1, fixedband=True, totBW=0.25e8,\n",
    "                 noisein=noisein, noiseout=noiseout, lowtemp=True, weightfreqspacing=1e3,\n",
    "                 k_th_AWG=k_th_AWG, \n",
    "                 k_th_w=k_th_w, k_th_out=k_th_out, \n",
    "                   k_th_A2D=k_th_A2D,\n",
    "                 scaletoz=False, scaletoW=False, wunits=1, unitconverter=1,\n",
    "                 includeinputfft=True, includeoutputfft=True, semianalog=True,\n",
    "                 digitallike=False, noisefactor=4, optics=False,\n",
    "                 photodiodearea=1e-6, omegaoptical=2*torch.pi*cbandfreq,\n",
    "                 inttime=1e-7, capval=1e-12, \n",
    "                  includecarrier=includecarrier, carrieroffmult=carrieroffmult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qr/rnwkjn_n61s9jtd8v591d8_h0000gn/T/ipykernel_46178/3630191390.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  delta_t = torch.tensor(1 / (omegac/(2*np.pi)), dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 done\n",
      "iteration 1 done\n",
      "iteration 2 done\n",
      "iteration 3 done\n",
      "iteration 4 done\n",
      "iteration 5 done\n",
      "iteration 6 done\n",
      "iteration 7 done\n",
      "iteration 8 done\n",
      "iteration 9 done\n",
      "iteration 10 done\n",
      "iteration 11 done\n",
      "iteration 12 done\n",
      "iteration 13 done\n",
      "iteration 14 done\n",
      "iteration 15 done\n"
     ]
    }
   ],
   "source": [
    "# inputsize = 256\n",
    "totalweightenergyrf_array = energiespermac*inputsize\n",
    "\n",
    "results_rf_all_nsr = []\n",
    "\n",
    "uni = True\n",
    "maxsnr = True\n",
    "\n",
    "if uni:\n",
    "    stddev = np.sqrt(1/3)\n",
    "else:\n",
    "    stddev = 1\n",
    "\n",
    "for idx, totalweightenergyrf in enumerate(totalweightenergyrf_array):\n",
    "    \n",
    "    results_rf = nsr_vs_energy(paramsrf, diodemixer, stddev=stddev, optics=False, \n",
    "                  inputsize=inputsize, outputsize=1, \n",
    "                  omegac=2*np.pi*UHFfreq, omegadiff=2*np.pi*UHFfreq, \n",
    "                  totalweightenergyopt=None, totalweightenergyrf=totalweightenergyrf,\n",
    "                  energiespermac=energiespermac, \n",
    "                               numtrials=200, \n",
    "                               uni=uni, \n",
    "                               maxsnr=maxsnr)\n",
    "    \n",
    "    results_rf_all_nsr.append([tensor.item() for tensor in results_rf])\n",
    "    print(f\"iteration {idx} done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENOBrf_nsr = 0.5*np.log(1+1/np.array(results_rf_all_nsr))/np.log(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_contour_with_dual_axes(start, end, ENOBrf_nsr, energiespermac, wbw=0.25e8, \n",
    "                            optics=False, dukeplot=False, uni=uni, maxsnr=maxsnr, \n",
    "                            noisein=noisein, noiseout=noiseout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(f\"ENOBrf_nsr_0.25e8_unimaxsnr_noisein_Jun4.json\", \"w\") as f:\n",
    "    json.dump(ENOBrf_nsr.tolist(), f)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "torchenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
